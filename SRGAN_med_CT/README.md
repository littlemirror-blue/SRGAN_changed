# SRGAN_med_CT
A PyTorch implementation of SRGAN based on CVPR 2017 paper , and fpr CT image super resolution.
[Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network](https://arxiv.org/abs/1609.04802).

## Requirements
- [Anaconda](https://www.anaconda.com/download/)
- PyTorch
```
conda install pytorch torchvision -c pytorch
```
- opencv
```
conda install opencv
```

## Datasets

### Train、Val Dataset | Test Image Dataset
all are sampled from [LUNA16](https://www.kaggle.com/datasets/avc0706/luna16/data)


## Usage

### Train
```
python train.py

optional arguments:
--crop_size                   training images crop size [default value is 88]
--upscale_factor              super resolution upscale factor [default value is 4](choices:[2, 4, 8])
--num_epochs                  train epoch number [default value is 100]
```
The output val super resolution images are on `training_results` directory.

### Test Benchmark Datasets
```
python test_benchmark.py

optional arguments:
--upscale_factor              super resolution upscale factor [default value is 4]
--model_name                  generator model epoch name [default value is netG_epoch_4_100.pth]
```
The output super resolution images are on `benchmark_results` directory.

### Test Single Image
```
python test_image.py

optional arguments:
--upscale_factor              super resolution upscale factor [default value is 4]
--test_mode                   using GPU or CPU [default value is 'GPU'](choices:['GPU', 'CPU'])
--image_name                  test low resolution image name
--model_name                  generator model epoch name [default value is netG_epoch_4_100.pth]
```
The output super resolution image are on the same directory.


## Benchmarks
**Upscale Factor = 2**

on a NVIDIA RTX 4060 GPU. 

> Image Results

DataSet,psnr,ssim
716498695101447665580610403574,30.072553525289344,0.9150850382344476
724251104254976962355686318345,30.2522660166007,0.9451358427806776
752756872840730509471096155114,30.777219912269214,0.9416957633701835
805925269324902055566754756843,28.238747107665446,0.9266620159994626
826812708000318290301835871780,29.946726792971276,0.9324458121958346
832260670372728970918746541371,29.556727616312465,0.9269139573986369
868211851413924881662621747734,29.905075835975722,0.9477029915263013
898642529028521482602829374444,30.055523376561425,0.9332621067762374
905371958588660410240398317235,31.060150063818497,0.946667516309964
975254950136384517744116790879,30.513461267151218,0.9442556043786388
979083010707182900091062408058,29.98698729565905,0.9346351948247027


**Upscale Factor = 4**



> Image Results

DataSet,psnr,ssim
716498695101447665580610403574,30.072553525289344,0.9150850382344476
724251104254976962355686318345,30.2522660166007,0.9451358427806776
752756872840730509471096155114,30.777219912269214,0.9416957633701835
805925269324902055566754756843,28.238747107665446,0.9266620159994626
826812708000318290301835871780,29.946726792971276,0.9324458121958346
832260670372728970918746541371,29.556727616312465,0.9269139573986369
868211851413924881662621747734,29.905075835975722,0.9477029915263013
898642529028521482602829374444,30.055523376561425,0.9332621067762374
905371958588660410240398317235,31.060150063818497,0.946667516309964
975254950136384517744116790879,30.513461267151218,0.9442556043786388
979083010707182900091062408058,29.98698729565905,0.9346351948247027


**Upscale Factor = 8**

> Image Results

DataSet,psnr,ssim
716498695101447665580610403574,30.072553525289344,0.9150850382344476
724251104254976962355686318345,30.2522660166007,0.9451358427806776
752756872840730509471096155114,30.777219912269214,0.9416957633701835
805925269324902055566754756843,28.238747107665446,0.9266620159994626
826812708000318290301835871780,29.946726792971276,0.9324458121958346
832260670372728970918746541371,29.556727616312465,0.9269139573986369
868211851413924881662621747734,29.905075835975722,0.9477029915263013
898642529028521482602829374444,30.055523376561425,0.9332621067762374
905371958588660410240398317235,31.060150063818497,0.946667516309964
975254950136384517744116790879,30.513461267151218,0.9442556043786388
979083010707182900091062408058,29.98698729565905,0.9346351948247027



